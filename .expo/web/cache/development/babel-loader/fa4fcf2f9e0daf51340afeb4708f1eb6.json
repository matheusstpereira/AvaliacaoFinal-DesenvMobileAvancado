{"ast":null,"code":"import _defineProperty from \"@babel/runtime/helpers/defineProperty\";\nimport _slicedToArray from \"@babel/runtime/helpers/slicedToArray\";\nfunction _createForOfIteratorHelperLoose(o, allowArrayLike) { var it = typeof Symbol !== \"undefined\" && o[Symbol.iterator] || o[\"@@iterator\"]; if (it) return (it = it.call(o)).next.bind(it); if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") { if (it) o = it; var i = 0; return function () { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); }\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\nfunction ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); enumerableOnly && (symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; })), keys.push.apply(keys, symbols); } return keys; }\nfunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = null != arguments[i] ? arguments[i] : {}; i % 2 ? ownKeys(Object(source), !0).forEach(function (key) { _defineProperty(target, key, source[key]); }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)) : ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } return target; }\nimport _regeneratorRuntime from \"@babel/runtime/regenerator\";\nimport * as React from 'react';\nimport * as Utils from \"./WebCameraUtils\";\nimport { FacingModeToCameraType } from \"./WebConstants\";\nvar VALID_SETTINGS_KEYS = ['autoFocus', 'flashMode', 'exposureCompensation', 'colorTemperature', 'iso', 'brightness', 'contrast', 'saturation', 'sharpness', 'focusDistance', 'whiteBalance', 'zoom'];\nfunction useLoadedVideo(video, onLoaded) {\n  React.useEffect(function () {\n    if (video) {\n      video.addEventListener('loadedmetadata', function () {\n        requestAnimationFrame(function () {\n          onLoaded();\n        });\n      });\n    }\n  }, [video]);\n}\nexport function useWebCameraStream(video, preferredType, settings, _ref) {\n  var onCameraReady = _ref.onCameraReady,\n    onMountError = _ref.onMountError;\n  var isStartingCamera = React.useRef(false);\n  var activeStreams = React.useRef([]);\n  var capabilities = React.useRef({\n    autoFocus: 'continuous',\n    flashMode: 'off',\n    whiteBalance: 'continuous',\n    zoom: 1\n  });\n  var _React$useState = React.useState(null),\n    _React$useState2 = _slicedToArray(_React$useState, 2),\n    stream = _React$useState2[0],\n    setStream = _React$useState2[1];\n  var mediaTrackSettings = React.useMemo(function () {\n    return stream ? stream.getTracks()[0].getSettings() : null;\n  }, [stream]);\n  var type = React.useMemo(function () {\n    if (!mediaTrackSettings) {\n      return null;\n    }\n    var _mediaTrackSettings$f = mediaTrackSettings.facingMode,\n      facingMode = _mediaTrackSettings$f === void 0 ? 'user' : _mediaTrackSettings$f;\n    return FacingModeToCameraType[facingMode];\n  }, [mediaTrackSettings]);\n  var getStreamDeviceAsync = React.useCallback(function _callee() {\n    return _regeneratorRuntime.async(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            _context.prev = 0;\n            _context.next = 3;\n            return _regeneratorRuntime.awrap(Utils.getPreferredStreamDevice(preferredType));\n          case 3:\n            return _context.abrupt(\"return\", _context.sent);\n          case 6:\n            _context.prev = 6;\n            _context.t0 = _context[\"catch\"](0);\n            if (__DEV__) {\n              console.warn(\"Error requesting UserMedia for type \\\"\" + preferredType + \"\\\":\", _context.t0);\n            }\n            if (onMountError) {\n              onMountError({\n                nativeEvent: _context.t0\n              });\n            }\n            return _context.abrupt(\"return\", null);\n          case 11:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, null, null, [[0, 6]], Promise);\n  }, [preferredType, onMountError]);\n  var resumeAsync = React.useCallback(function _callee2() {\n    var nextStream;\n    return _regeneratorRuntime.async(function _callee2$(_context2) {\n      while (1) {\n        switch (_context2.prev = _context2.next) {\n          case 0:\n            _context2.next = 2;\n            return _regeneratorRuntime.awrap(getStreamDeviceAsync());\n          case 2:\n            nextStream = _context2.sent;\n            if (!Utils.compareStreams(nextStream, stream)) {\n              _context2.next = 5;\n              break;\n            }\n            return _context2.abrupt(\"return\", false);\n          case 5:\n            if (!activeStreams.current.some(function (value) {\n              return value.id === (nextStream == null ? void 0 : nextStream.id);\n            })) {\n              activeStreams.current.push(nextStream);\n            }\n            setStream(nextStream);\n            if (onCameraReady) {\n              onCameraReady();\n            }\n            return _context2.abrupt(\"return\", false);\n          case 9:\n          case \"end\":\n            return _context2.stop();\n        }\n      }\n    }, null, null, null, Promise);\n  }, [getStreamDeviceAsync, setStream, onCameraReady, stream, activeStreams.current]);\n  React.useEffect(function () {\n    if (isStartingCamera.current) {\n      return;\n    }\n    isStartingCamera.current = true;\n    resumeAsync().then(function (isStarting) {\n      isStartingCamera.current = isStarting;\n    }).catch(function () {\n      isStartingCamera.current = false;\n    });\n  }, [preferredType]);\n  React.useEffect(function () {\n    var changes = {};\n    for (var _i = 0, _Object$keys = Object.keys(settings); _i < _Object$keys.length; _i++) {\n      var key = _Object$keys[_i];\n      if (!VALID_SETTINGS_KEYS.includes(key)) {\n        continue;\n      }\n      var nextValue = settings[key];\n      if (nextValue !== capabilities.current[key]) {\n        changes[key] = nextValue;\n      }\n    }\n    var hasChanges = !!Object.keys(changes).length;\n    var nextWebCameraSettings = _objectSpread(_objectSpread({}, capabilities.current), changes);\n    if (hasChanges) {\n      Utils.syncTrackCapabilities(preferredType, stream, changes);\n    }\n    capabilities.current = nextWebCameraSettings;\n  }, [settings.autoFocus, settings.flashMode, settings.exposureCompensation, settings.colorTemperature, settings.iso, settings.brightness, settings.contrast, settings.saturation, settings.sharpness, settings.focusDistance, settings.whiteBalance, settings.zoom]);\n  React.useEffect(function () {\n    if (!video.current) {\n      return;\n    }\n    Utils.setVideoSource(video.current, stream);\n  }, [video.current, stream]);\n  React.useEffect(function () {\n    return function () {\n      for (var _iterator = _createForOfIteratorHelperLoose(activeStreams.current), _step; !(_step = _iterator()).done;) {\n        var _stream = _step.value;\n        Utils.stopMediaStream(_stream);\n      }\n      if (video.current) {\n        Utils.setVideoSource(video.current, stream);\n      }\n    };\n  }, []);\n  useLoadedVideo(video.current, function () {\n    Utils.syncTrackCapabilities(preferredType, stream, capabilities.current);\n  });\n  return {\n    type: type,\n    mediaTrackSettings: mediaTrackSettings\n  };\n}","map":{"version":3,"mappings":";;;;;;;;AACA,OAAO,KAAKA,KAAK,MAAM,OAAO;AAQ9B,OAAO,KAAKC,KAAK;AACjB,SAASC,sBAAsB;AAE/B,IAAMC,mBAAmB,GAAG,CAC1B,WAAW,EACX,WAAW,EACX,sBAAsB,EACtB,kBAAkB,EAClB,KAAK,EACL,YAAY,EACZ,UAAU,EACV,YAAY,EACZ,WAAW,EACX,eAAe,EACf,cAAc,EACd,MAAM,CACP;AAED,SAASC,cAAc,CAACC,KAA8B,EAAEC,QAAoB;EAC1EN,KAAK,CAACO,SAAS,CAAC,YAAK;IACnB,IAAIF,KAAK,EAAE;MACTA,KAAK,CAACG,gBAAgB,CAAC,gBAAgB,EAAE,YAAK;QAI5CC,qBAAqB,CAAC,YAAK;UACzBH,QAAQ,EAAE;QACZ,CAAC,CAAC;MACJ,CAAC,CAAC;;EAEN,CAAC,EAAE,CAACD,KAAK,CAAC,CAAC;AACb;AAEA,OAAM,SAAUK,kBAAkB,CAChCL,KAAsD,EACtDM,aAAyB,EACzBC,QAA6B,QAIgD;EAAA,IAF3EC,aAAa,QAAbA,aAAa;IACbC,YAAY,QAAZA,YAAY;EAMd,IAAMC,gBAAgB,GAAGf,KAAK,CAACgB,MAAM,CAAiB,KAAK,CAAC;EAC5D,IAAMC,aAAa,GAAGjB,KAAK,CAACgB,MAAM,CAAgB,EAAE,CAAC;EACrD,IAAME,YAAY,GAAGlB,KAAK,CAACgB,MAAM,CAAoB;IACnDG,SAAS,EAAE,YAAY;IACvBC,SAAS,EAAE,KAAK;IAChBC,YAAY,EAAE,YAAY;IAC1BC,IAAI,EAAE;GACP,CAAC;EACF,sBAA4BtB,KAAK,CAACuB,QAAQ,CAAqB,IAAI,CAAC;IAAA;IAA7DC,MAAM;IAAEC,SAAS;EAExB,IAAMC,kBAAkB,GAAG1B,KAAK,CAAC2B,OAAO,CAAC,YAAK;IAC5C,OAAOH,MAAM,GAAGA,MAAM,CAACI,SAAS,EAAE,CAAC,CAAC,CAAC,CAACC,WAAW,EAAE,GAAG,IAAI;EAC5D,CAAC,EAAE,CAACL,MAAM,CAAC,CAAC;EAGZ,IAAMM,IAAI,GAAG9B,KAAK,CAAC2B,OAAO,CAAC,YAAK;IAC9B,IAAI,CAACD,kBAAkB,EAAE;MACvB,OAAO,IAAI;;IAGb,4BAAgCA,kBAAkB,CAA1CK,UAAU;MAAVA,UAAU,sCAAG,MAAM;IAC3B,OAAO7B,sBAAsB,CAAC6B,UAAU,CAAC;EAC3C,CAAC,EAAE,CAACL,kBAAkB,CAAC,CAAC;EAExB,IAAMM,oBAAoB,GAAGhC,KAAK,CAACiC,WAAW,CAAC;IAAA;MAAA;QAAA;UAAA;YAAA;YAAA;YAAA,iCAE9BhC,KAAK,CAACiC,wBAAwB,CAACvB,aAAa,CAAC;UAAA;YAAA;UAAA;YAAA;YAAA;YAE1D,IAAIwB,OAAO,EAAE;cACXC,OAAO,CAACC,IAAI,4CAAyC1B,aAAa,sBAAkB;;YAEtF,IAAIG,YAAY,EAAE;cAChBA,YAAY,CAAC;gBAAEwB,WAAW;cAAA,CAAE,CAAC;;YAC9B,iCACM,IAAI;UAAA;UAAA;YAAA;QAAA;MAAA;IAAA;EAAA,CAEd,EAAE,CAAC3B,aAAa,EAAEG,YAAY,CAAC,CAAC;EAEjC,IAAMyB,WAAW,GAAGvC,KAAK,CAACiC,WAAW,CAAC;IAAA;IAAA;MAAA;QAAA;UAAA;YAAA;YAAA,iCACXD,oBAAoB,EAAE;UAAA;YAAzCQ,UAAU;YAAA,KACZvC,KAAK,CAACwC,cAAc,CAACD,UAAU,EAAEhB,MAAM,CAAC;cAAA;cAAA;YAAA;YAAA,kCAInC,KAAK;UAAA;YAKd,IAAI,CAACP,aAAa,CAACyB,OAAO,CAACC,IAAI,CAAC,UAACC,KAAK;cAAA,OAAKA,KAAK,CAACC,EAAE,MAAKL,UAAU,oBAAVA,UAAU,CAAEK,EAAE;YAAA,EAAC,EAAE;cACvE5B,aAAa,CAACyB,OAAO,CAACI,IAAI,CAACN,UAAW,CAAC;;YAIzCf,SAAS,CAACe,UAAU,CAAC;YACrB,IAAI3B,aAAa,EAAE;cACjBA,aAAa,EAAE;;YAChB,kCACM,KAAK;UAAA;UAAA;YAAA;QAAA;MAAA;IAAA;EAAA,CACb,EAAE,CAACmB,oBAAoB,EAAEP,SAAS,EAAEZ,aAAa,EAAEW,MAAM,EAAEP,aAAa,CAACyB,OAAO,CAAC,CAAC;EAEnF1C,KAAK,CAACO,SAAS,CAAC,YAAK;IAEnB,IAAIQ,gBAAgB,CAAC2B,OAAO,EAAE;MAC5B;;IAEF3B,gBAAgB,CAAC2B,OAAO,GAAG,IAAI;IAE/BH,WAAW,EAAE,CACVQ,IAAI,CAAC,UAACC,UAAU,EAAI;MACnBjC,gBAAgB,CAAC2B,OAAO,GAAGM,UAAU;IACvC,CAAC,CAAC,CACDC,KAAK,CAAC,YAAK;MAEVlC,gBAAgB,CAAC2B,OAAO,GAAG,KAAK;IAClC,CAAC,CAAC;EACN,CAAC,EAAE,CAAC/B,aAAa,CAAC,CAAC;EAGnBX,KAAK,CAACO,SAAS,CAAC,YAAK;IACnB,IAAM2C,OAAO,GAAsB,EAAE;IAErC,gCAAkBC,MAAM,CAACC,IAAI,CAACxC,QAAQ,CAAC,kCAAE;MAApC,IAAMyC,GAAG;MACZ,IAAI,CAAClD,mBAAmB,CAACmD,QAAQ,CAACD,GAAG,CAAC,EAAE;QACtC;;MAEF,IAAME,SAAS,GAAG3C,QAAQ,CAACyC,GAAG,CAAC;MAC/B,IAAIE,SAAS,KAAKrC,YAAY,CAACwB,OAAO,CAACW,GAAG,CAAC,EAAE;QAC3CH,OAAO,CAACG,GAAG,CAAC,GAAGE,SAAS;;;IAK5B,IAAMC,UAAU,GAAG,CAAC,CAACL,MAAM,CAACC,IAAI,CAACF,OAAO,CAAC,CAACO,MAAM;IAEhD,IAAMC,qBAAqB,mCAAQxC,YAAY,CAACwB,OAAO,GAAKQ,OAAO,CAAE;IACrE,IAAIM,UAAU,EAAE;MACdvD,KAAK,CAAC0D,qBAAqB,CAAChD,aAAa,EAAEa,MAAM,EAAE0B,OAAO,CAAC;;IAG7DhC,YAAY,CAACwB,OAAO,GAAGgB,qBAAqB;EAC9C,CAAC,EAAE,CACD9C,QAAQ,CAACO,SAAS,EAClBP,QAAQ,CAACQ,SAAS,EAClBR,QAAQ,CAACgD,oBAAoB,EAC7BhD,QAAQ,CAACiD,gBAAgB,EACzBjD,QAAQ,CAACkD,GAAG,EACZlD,QAAQ,CAACmD,UAAU,EACnBnD,QAAQ,CAACoD,QAAQ,EACjBpD,QAAQ,CAACqD,UAAU,EACnBrD,QAAQ,CAACsD,SAAS,EAClBtD,QAAQ,CAACuD,aAAa,EACtBvD,QAAQ,CAACS,YAAY,EACrBT,QAAQ,CAACU,IAAI,CACd,CAAC;EAEFtB,KAAK,CAACO,SAAS,CAAC,YAAK;IAEnB,IAAI,CAACF,KAAK,CAACqC,OAAO,EAAE;MAClB;;IAEFzC,KAAK,CAACmE,cAAc,CAAC/D,KAAK,CAACqC,OAAO,EAAElB,MAAM,CAAC;EAC7C,CAAC,EAAE,CAACnB,KAAK,CAACqC,OAAO,EAAElB,MAAM,CAAC,CAAC;EAE3BxB,KAAK,CAACO,SAAS,CAAC,YAAK;IACnB,OAAO,YAAK;MAEV,qDAAqBU,aAAa,CAACyB,OAAO,wCAAE;QAAA,IAAjClB,OAAM;QAEfvB,KAAK,CAACoE,eAAe,CAAC7C,OAAM,CAAC;;MAE/B,IAAInB,KAAK,CAACqC,OAAO,EAAE;QAEjBzC,KAAK,CAACmE,cAAc,CAAC/D,KAAK,CAACqC,OAAO,EAAElB,MAAM,CAAC;;IAE/C,CAAC;EACH,CAAC,EAAE,EAAE,CAAC;EAGNpB,cAAc,CAACC,KAAK,CAACqC,OAAO,EAAE,YAAK;IACjCzC,KAAK,CAAC0D,qBAAqB,CAAChD,aAAa,EAAEa,MAAM,EAAEN,YAAY,CAACwB,OAAO,CAAC;EAC1E,CAAC,CAAC;EAEF,OAAO;IACLZ,IAAI,EAAJA,IAAI;IACJJ,kBAAkB,EAAlBA;GACD;AACH","names":["React","Utils","FacingModeToCameraType","VALID_SETTINGS_KEYS","useLoadedVideo","video","onLoaded","useEffect","addEventListener","requestAnimationFrame","useWebCameraStream","preferredType","settings","onCameraReady","onMountError","isStartingCamera","useRef","activeStreams","capabilities","autoFocus","flashMode","whiteBalance","zoom","useState","stream","setStream","mediaTrackSettings","useMemo","getTracks","getSettings","type","facingMode","getStreamDeviceAsync","useCallback","getPreferredStreamDevice","__DEV__","console","warn","nativeEvent","resumeAsync","nextStream","compareStreams","current","some","value","id","push","then","isStarting","catch","changes","Object","keys","key","includes","nextValue","hasChanges","length","nextWebCameraSettings","syncTrackCapabilities","exposureCompensation","colorTemperature","iso","brightness","contrast","saturation","sharpness","focusDistance","setVideoSource","stopMediaStream"],"sourceRoot":"","sources":["../src/useWebCameraStream.ts"],"sourcesContent":["/* eslint-env browser */\nimport * as React from 'react';\n\nimport {\n  CameraReadyListener,\n  CameraType,\n  MountErrorListener,\n  WebCameraSettings,\n} from './Camera.types';\nimport * as Utils from './WebCameraUtils';\nimport { FacingModeToCameraType } from './WebConstants';\n\nconst VALID_SETTINGS_KEYS = [\n  'autoFocus',\n  'flashMode',\n  'exposureCompensation',\n  'colorTemperature',\n  'iso',\n  'brightness',\n  'contrast',\n  'saturation',\n  'sharpness',\n  'focusDistance',\n  'whiteBalance',\n  'zoom',\n];\n\nfunction useLoadedVideo(video: HTMLVideoElement | null, onLoaded: () => void) {\n  React.useEffect(() => {\n    if (video) {\n      video.addEventListener('loadedmetadata', () => {\n        // without this async block the constraints aren't properly applied to the camera,\n        // this means that if you were to turn on the torch and swap to the front camera,\n        // then swap back to the rear camera the torch setting wouldn't be applied.\n        requestAnimationFrame(() => {\n          onLoaded();\n        });\n      });\n    }\n  }, [video]);\n}\n\nexport function useWebCameraStream(\n  video: React.MutableRefObject<HTMLVideoElement | null>,\n  preferredType: CameraType,\n  settings: Record<string, any>,\n  {\n    onCameraReady,\n    onMountError,\n  }: { onCameraReady?: CameraReadyListener; onMountError?: MountErrorListener }\n): {\n  type: CameraType | null;\n  mediaTrackSettings: MediaTrackSettings | null;\n} {\n  const isStartingCamera = React.useRef<boolean | null>(false);\n  const activeStreams = React.useRef<MediaStream[]>([]);\n  const capabilities = React.useRef<WebCameraSettings>({\n    autoFocus: 'continuous',\n    flashMode: 'off',\n    whiteBalance: 'continuous',\n    zoom: 1,\n  });\n  const [stream, setStream] = React.useState<MediaStream | null>(null);\n\n  const mediaTrackSettings = React.useMemo(() => {\n    return stream ? stream.getTracks()[0].getSettings() : null;\n  }, [stream]);\n\n  // The actual camera type - this can be different from the incoming camera type.\n  const type = React.useMemo(() => {\n    if (!mediaTrackSettings) {\n      return null;\n    }\n    // On desktop no value will be returned, in this case we should assume the cameraType is 'front'\n    const { facingMode = 'user' } = mediaTrackSettings;\n    return FacingModeToCameraType[facingMode];\n  }, [mediaTrackSettings]);\n\n  const getStreamDeviceAsync = React.useCallback(async (): Promise<MediaStream | null> => {\n    try {\n      return await Utils.getPreferredStreamDevice(preferredType);\n    } catch (nativeEvent) {\n      if (__DEV__) {\n        console.warn(`Error requesting UserMedia for type \"${preferredType}\":`, nativeEvent);\n      }\n      if (onMountError) {\n        onMountError({ nativeEvent });\n      }\n      return null;\n    }\n  }, [preferredType, onMountError]);\n\n  const resumeAsync = React.useCallback(async (): Promise<boolean> => {\n    const nextStream = await getStreamDeviceAsync();\n    if (Utils.compareStreams(nextStream, stream)) {\n      // Do nothing if the streams are the same.\n      // This happens when the device only supports one camera (i.e. desktop) and the mode was toggled between front/back while already active.\n      // Without this check there is a screen flash while the video switches.\n      return false;\n    }\n\n    // Save a history of all active streams (usually 2+) so we can close them later.\n    // Keeping them open makes swapping camera types much faster.\n    if (!activeStreams.current.some((value) => value.id === nextStream?.id)) {\n      activeStreams.current.push(nextStream!);\n    }\n\n    // Set the new stream -> update the video, settings, and actual camera type.\n    setStream(nextStream);\n    if (onCameraReady) {\n      onCameraReady();\n    }\n    return false;\n  }, [getStreamDeviceAsync, setStream, onCameraReady, stream, activeStreams.current]);\n\n  React.useEffect(() => {\n    // Restart the camera and guard concurrent actions.\n    if (isStartingCamera.current) {\n      return;\n    }\n    isStartingCamera.current = true;\n\n    resumeAsync()\n      .then((isStarting) => {\n        isStartingCamera.current = isStarting;\n      })\n      .catch(() => {\n        // ensure the camera can be started again.\n        isStartingCamera.current = false;\n      });\n  }, [preferredType]);\n\n  // Update the native camera with any custom capabilities.\n  React.useEffect(() => {\n    const changes: WebCameraSettings = {};\n\n    for (const key of Object.keys(settings)) {\n      if (!VALID_SETTINGS_KEYS.includes(key)) {\n        continue;\n      }\n      const nextValue = settings[key];\n      if (nextValue !== capabilities.current[key]) {\n        changes[key] = nextValue;\n      }\n    }\n\n    // Only update the native camera if changes were found\n    const hasChanges = !!Object.keys(changes).length;\n\n    const nextWebCameraSettings = { ...capabilities.current, ...changes };\n    if (hasChanges) {\n      Utils.syncTrackCapabilities(preferredType, stream, changes);\n    }\n\n    capabilities.current = nextWebCameraSettings;\n  }, [\n    settings.autoFocus,\n    settings.flashMode,\n    settings.exposureCompensation,\n    settings.colorTemperature,\n    settings.iso,\n    settings.brightness,\n    settings.contrast,\n    settings.saturation,\n    settings.sharpness,\n    settings.focusDistance,\n    settings.whiteBalance,\n    settings.zoom,\n  ]);\n\n  React.useEffect(() => {\n    // set or unset the video source.\n    if (!video.current) {\n      return;\n    }\n    Utils.setVideoSource(video.current, stream);\n  }, [video.current, stream]);\n\n  React.useEffect(() => {\n    return () => {\n      // Clean up on dismount, this is important for making sure the camera light goes off when the component is removed.\n      for (const stream of activeStreams.current) {\n        // Close all open streams.\n        Utils.stopMediaStream(stream);\n      }\n      if (video.current) {\n        // Invalidate the video source.\n        Utils.setVideoSource(video.current, stream);\n      }\n    };\n  }, []);\n\n  // Update props when the video loads.\n  useLoadedVideo(video.current, () => {\n    Utils.syncTrackCapabilities(preferredType, stream, capabilities.current);\n  });\n\n  return {\n    type,\n    mediaTrackSettings,\n  };\n}\n"]},"metadata":{},"sourceType":"module"}